{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  FooCars Step By Step",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcipolina/foocars/blob/lucia/Copy_of_FooCars_Step_By_Step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ejv-Jt8D__",
        "colab_type": "text"
      },
      "source": [
        "# What is Foocars and why should I care?\n",
        "\n",
        "Foocars is an inexpensive open source autonomous car driving system. It uses machine learning to create a robust method of driving cars around cones and obstaces.  \"Cars\" is broad term in this case. It's been used on toy cars, RC Cars, and single seater Power Wheels vehicles. This is an extremely low cost and robust option to get started in understanding autonomous vehicles.\n",
        "\n",
        "For this project we''ll use the RC car version and work out how the car trains and later makes decisions based on the collected training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0tGN0AY84dj",
        "colab_type": "text"
      },
      "source": [
        "# The Foocars project \n",
        "\n",
        "It's located here: https://foocars.io\n",
        "\n",
        "The main working repository for the project is here: https://github.com/fubarlabs/foocars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugfhzhg35_PD",
        "colab_type": "text"
      },
      "source": [
        "# The Code\n",
        "This code implements Machine Learning techniques to generate an algorithm that allows a car to take driving decisions autonomously. \n",
        "The  algorithm is capable of identifying obstacles on a racing circuit allowing the car to avoid them.  \n",
        "\n",
        "To calibrate (i.e. train) the algorithm we use pre-recorded images of obstacles usually found on a racing circuit. We process the images using Convolutional Neuronal Networks and obtain a set of parameters that are used by the car in real time to take steering decisions while racing. \n",
        "\n",
        "The code is divided in the following sections:\n",
        "\n",
        "* Uploading the image data from an external repository\n",
        "* Training the Convolutional Neuronal Networks using Python.\n",
        "* Analizing the results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeFu_EZvEW7I",
        "colab_type": "text"
      },
      "source": [
        "# Uploading the Training Data\n",
        "The aim of this code is to train a Convolutional Neuronal Network to identify obtacles. We present the Network with a set of example objects and through iteration, it generates al algorithm to identify patters in the data. This allows us to classify objects into different kind of obstacles to be avoided (i.er. a cone, a shoe , a chair, etc).\n",
        "\n",
        "We store the collected data in an external repository. The most convenient way of sharing data is to create a public folder in Google Drive.\n",
        "\n",
        "This part of the code does the following:\n",
        "* Uses pipenv to create a Virtual Environment.\n",
        "* Downloads the image data and extracts it into a dedicated folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gEJpmY0GGMz",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:** Change this to point the global variables to where the image data is located"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O40jGjx6do7Y",
        "colab_type": "code",
        "outputId": "14a2ed51-676c-4c39-a092-dfb4a281314c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%env USERNAME=lcipolina\n",
        "!echo $USERNAME\n",
        "!echo https://github.com/$USERNAME/foocars.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: USERNAME=lcipolina\n",
            "lcipolina\n",
            "https://github.com/lcipolina/foocars.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRiHlWWiGXp6",
        "colab_type": "text"
      },
      "source": [
        "We will make a local copy  (i.e. a clone) of the data repository. \n",
        "Previous to this, please create your own Fork of the project's main Repo in GitHub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUMSIJwy9KB1",
        "colab_type": "code",
        "outputId": "ef497e5b-cba3-465c-d057-68ec97bbce65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Cloning our own Fork of the project to our local repo.\n",
        "!git clone https://github.com/$USERNAME/foocars.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'foocars'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 4088 (delta 9), reused 3 (delta 0), pack-reused 4071\u001b[K\n",
            "Receiving objects: 100% (4088/4088), 160.73 MiB | 34.42 MiB/s, done.\n",
            "Resolving deltas: 100% (2282/2282), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n2KtTT19Uwb",
        "colab_type": "code",
        "outputId": "fcf1e94f-c80f-4f2b-c547-169d407a89ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "foocars  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53ESA5-9b6A",
        "colab_type": "code",
        "outputId": "d69f1e9d-ac2c-4cc3-c69d-b4f3354e52c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#we will install pipenv in foocars directory\n",
        "%cd foocars"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/foocars\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir42Fo1ugl4L",
        "colab_type": "code",
        "outputId": "251cb973-433b-412e-8f7b-d239283acf6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cars\t\t  installation.md  schematics\t   training\n",
            "Dockerfile-car\t  Pipfile\t   setuppython.sh  utilities\n",
            "Dockerfile-train  README.md\t   tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1NzgqW9ihz",
        "colab_type": "code",
        "outputId": "f3082eee-b8e0-4462-bfe8-ca761b171857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "#install pipenv in \"foocars\" directory\n",
        "!pip install pipenv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pipenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/b4/3ffa55f77161cff9a5220f162670f7c5eb00df52e00939e203f601b0f579/pipenv-2018.11.26-py3-none-any.whl (5.2MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip>=9.0.1 in /usr/local/lib/python3.6/dist-packages (from pipenv) (19.1.1)\n",
            "Collecting virtualenv-clone>=0.2.5 (from pipenv)\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/f8/50c2b7dbc99e05fce5e5b9d9a31f37c988c99acd4e8dedd720b7b8d4011d/virtualenv_clone-0.5.3-py2.py3-none-any.whl\n",
            "Collecting virtualenv (from pipenv)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ee/8375c01412abe6ff462ec80970e6bb1c4308724d4366d7519627c98691ab/virtualenv-16.6.0-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=36.2.1 in /usr/local/lib/python3.6/dist-packages (from pipenv) (41.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pipenv) (2019.3.9)\n",
            "Installing collected packages: virtualenv-clone, virtualenv, pipenv\n",
            "Successfully installed pipenv-2018.11.26 virtualenv-16.6.0 virtualenv-clone-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aK-nROT9tBC",
        "colab_type": "code",
        "outputId": "99ec5c69-f778-432e-d98a-15e8de94283d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "#Create virtual environment in the folder we are in \n",
        "!pipenv install "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m\u001b[1mCreating a virtualenv for this project…\u001b[39m\u001b[22m\n",
            "Pipfile: \u001b[31m\u001b[1m/content/foocars/Pipfile\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mUsing\u001b[39m\u001b[22m \u001b[31m\u001b[1m/usr/local/bin/python\u001b[39m\u001b[22m \u001b[32m\u001b[22m(3.6.7)\u001b[39m\u001b[22m \u001b[39m\u001b[1mto create virtualenv…\u001b[39m\u001b[22m\n",
            "⠇\u001b[0m Creating virtual environment...\u001b[K\u001b[34m\u001b[22mUsing base prefix '/usr'\n",
            "New python executable in /root/.local/share/virtualenvs/foocars--MKvUarz/bin/python3\n",
            "Also creating executable in /root/.local/share/virtualenvs/foocars--MKvUarz/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n",
            "Running virtualenv with interpreter /usr/local/bin/python\n",
            "\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[32m\u001b[22m✔ Successfully created virtual environment!\u001b[39m\u001b[22m\u001b[0m \n",
            "Virtualenv location: \u001b[32m\u001b[22m/root/.local/share/virtualenvs/foocars--MKvUarz\u001b[39m\u001b[22m\n",
            "\u001b[31m\u001b[1mWarning\u001b[39m\u001b[22m: Your Pipfile requires \u001b[39m\u001b[1mpython_version\u001b[39m\u001b[22m \u001b[34m\u001b[22m3.*\u001b[39m\u001b[22m, but you are using \u001b[34m\u001b[22m3.6.7\u001b[39m\u001b[22m (\u001b[32m\u001b[22m/root/.local/share/v/f/bin/python\u001b[39m\u001b[22m).\n",
            "  \u001b[32m\u001b[22m$ pipenv --rm\u001b[39m\u001b[22m and rebuilding the virtual environment may resolve the issue.\n",
            "  \u001b[31m\u001b[22m$ pipenv check\u001b[39m\u001b[22m will surely fail.\n",
            "\u001b[39m\u001b[1mPipfile.lock not found, creating…\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[31m\u001b[22m[dev-packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies…\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[31m\u001b[22m[packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies…\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[32m\u001b[22m✔ Success!\u001b[39m\u001b[22m\u001b[0m \n",
            "\u001b[39m\u001b[1mUpdated Pipfile.lock (3c28c2)!\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (3c28c2)…\u001b[39m\u001b[22m\n",
            "  🐍   \u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m 27/27 — \u001b[30m\u001b[22m00:00:12\u001b[39m\u001b[22m\n",
            "To activate this project's virtualenv, run \u001b[31m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
            "Alternatively, run a command inside the virtualenv with \u001b[31m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zJCnLtRw94V",
        "colab_type": "code",
        "outputId": "5679a19e-a1fc-4a0d-ed1b-7bee427a447d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cars\t\t  installation.md  README.md\t   tests\n",
            "Dockerfile-car\t  Pipfile\t   schematics\t   training\n",
            "Dockerfile-train  Pipfile.lock\t   setuppython.sh  utilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcBiq0QU9pAZ",
        "colab_type": "code",
        "outputId": "83b3c935-171f-4d1c-ea31-e34e0392d0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Create folder /steelroses\n",
        "#Download data file in folder  /content/data/cars/steelroses/collected\n",
        "!mkdir -p /content/data/cars/steelroses\n",
        "%cd /content/data/cars/steelroses"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/cars/steelroses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5mwdLnDCJWb",
        "colab_type": "code",
        "outputId": "6ecf7243-8936-44e5-9275-0108bb8d5850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Load data from a shared folder in Google Drive\n",
        "# Tutorial: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "\n",
        "import pdb #used to debug\n",
        "import tarfile\n",
        "\n",
        "fileID='https://drive.google.com/open?id=1jtW5aSS6dj1DNmxr87iHf1bzkBB1A3Km' # The shareable link to steelroses data\n",
        "file = 'steelroses.collected.tar.gz'\n",
        "\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth  import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab  import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth             = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive             = GoogleDrive(gauth)\n",
        "link              = fileID\n",
        "fluff, id         = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded        = drive.CreateFile({'id':id}) \n",
        "\n",
        "downloaded.GetContentFile('steelroses.collected.tar.gz') \n",
        "\n",
        "#tar = tarfile.open(file , \"r:gz\")\n",
        "#Uncompress file in folder  'foocars/collected'\n",
        "#!tar xvzf steelroses.collected.tar.gz #verbose\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "1jtW5aSS6dj1DNmxr87iHf1bzkBB1A3Km\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E30mQKMDy8Bx",
        "colab_type": "code",
        "outputId": "bb1e0cc2-786e-4ce4-cdb4-958d36a78110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Extracts the data file in the folder:  /content/data/cars/steelroses/collected\n",
        "%cd /content/data/cars/steelroses\n",
        "!tar xzf steelroses.collected.tar.gz #not verbose"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/cars/steelroses\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjSs9u6-HJ4i",
        "colab_type": "code",
        "outputId": "b2705178-ba97-40ee-ca31-52deab3c4ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collected  steelroses.collected.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSEd47PrsSHV",
        "colab_type": "text"
      },
      "source": [
        "# Environment is setup\n",
        "\n",
        "We can run the software for training. But first we need to map the data to be accessible.\n",
        "\n",
        " 1. Get g drive access to a cars curated training data\n",
        " 2. Take a look at some of the images\n",
        " 3. Train on the data set\n",
        " 4. Select steerstats \n",
        " 5. Experiement let's look at steer stats\n",
        " 6. What happens when we give it an image, what prediction is made\n",
        " 7. Download the weights and steerstats to the car\n",
        " 8. Test by running on the car"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcF3R4ARqjGb",
        "colab_type": "code",
        "outputId": "0c2eb6c2-d9c5-4fe8-b55d-88def2a3d23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#TRAIN THE MODEL\n",
        "# Go to folder where the training function is\n",
        "%cd /content/foocars/training/\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/foocars/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28cJhOcRbc8R",
        "colab_type": "code",
        "outputId": "7d5756ae-8a68-4efe-efbc-1322e0bec96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defines.py\t  history_model.py  train_history.py\n",
            "dropout_model.py  readme.md\t    train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEGSnMWUIxRa",
        "colab_type": "text"
      },
      "source": [
        "# Description of a Convolutional Neuronal Network\n",
        "\n",
        "A Convolutional Neuronal Network is a common type of Neuronal Network used in image processing. The idea is to apply image filters in a smart way to reduce the size of images and make them more tractable. Additionally, by removing irrelevant data, the object's main features are highlighted, improving the accuracy of the object recognition algorithm. \n",
        "\n",
        "The smart filters are just mathematical operations applied in secuential order to reduce dimensions without losing accuracy.\n",
        "\n",
        "After the convolution has been applied, the resulting images are passed to the traditional Neuronal Networks to train the classification parameters.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VCQ40OXIARP",
        "colab_type": "text"
      },
      "source": [
        "#Train the Convolutional Neuronal Network\n",
        "\n",
        "We will use 'pipenv' to run the function inside the script 'train.py'.\n",
        "\n",
        "We need to define some variables needed by the function. Below we provide example values.:\n",
        "\n",
        "* Number of epochs:   --epochs 10 \n",
        "* --save_frequency 2 \n",
        "* path to data: \n",
        "/content/data/cars/steelroses/collected \n",
        "\n",
        "### The output of a Convolutional Neuronal Network run in Keras:\n",
        "The python code below outputs the result of the following operations:\n",
        "\n",
        "\n",
        "*  'conv2d' - Applies a 'convolution' operation (which is just a matrix by matrix multiplication) to reduce the matrix's dimension. \n",
        "\n",
        "* 'dropout'  - Is the implementation of the \"dropout technique\" to reduce parameter overfitting while preserving accuracy and classification power.\n",
        "\n",
        "* 'Flatten'  - Is used to create back a single array of data after the previous operations have been applied.\n",
        "\n",
        "These two opeations are applied iterated sequantially until a desired level or classification error is achieved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qHVj6LJ0PsO",
        "colab_type": "code",
        "outputId": "3b873e2e-130e-4f76-fcbf-b7f12ca5255d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "!pipenv install numpy\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWarning\u001b[39m\u001b[22m: Your Pipfile requires \u001b[39m\u001b[1mpython_version\u001b[39m\u001b[22m \u001b[34m\u001b[22m3.*\u001b[39m\u001b[22m, but you are using \u001b[34m\u001b[22m3.6.7\u001b[39m\u001b[22m (\u001b[32m\u001b[22m/root/.local/share/v/f/bin/python\u001b[39m\u001b[22m).\n",
            "  \u001b[32m\u001b[22m$ pipenv --rm\u001b[39m\u001b[22m and rebuilding the virtual environment may resolve the issue.\n",
            "  \u001b[31m\u001b[22m$ pipenv check\u001b[39m\u001b[22m will surely fail.\n",
            "\u001b[39m\u001b[1mInstalling \u001b[32m\u001b[1mnumpy\u001b[39m\u001b[22m…\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[39m\u001b[1mAdding\u001b[39m\u001b[22m \u001b[32m\u001b[1mnumpy\u001b[39m\u001b[22m \u001b[39m\u001b[1mto Pipfile's\u001b[39m\u001b[22m \u001b[31m\u001b[1m[packages]\u001b[39m\u001b[22m\u001b[39m\u001b[1m…\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h✔ Installation Succeeded\u001b[0m \n",
            "\u001b[31m\u001b[1mPipfile.lock (426ee3) out of date, updating to (3c28c2)…\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[31m\u001b[22m[dev-packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies…\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[22mLocking\u001b[39m\u001b[22m \u001b[31m\u001b[22m[packages]\u001b[39m\u001b[22m \u001b[39m\u001b[22mdependencies…\u001b[39m\u001b[22m\n",
            "\u001b[K\u001b[?25h\u001b[32m\u001b[22m✔ Success!\u001b[39m\u001b[22m\u001b[0m \n",
            "\u001b[39m\u001b[1mUpdated Pipfile.lock (426ee3)!\u001b[39m\u001b[22m\n",
            "\u001b[39m\u001b[1mInstalling dependencies from Pipfile.lock (426ee3)…\u001b[39m\u001b[22m\n",
            "  🐍   \u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m\u001b[32m\u001b[1m▉\u001b[39m\u001b[22m 27/27 — \u001b[30m\u001b[22m00:00:09\u001b[39m\u001b[22m\n",
            "To activate this project's virtualenv, run \u001b[31m\u001b[22mpipenv shell\u001b[39m\u001b[22m.\n",
            "Alternatively, run a command inside the virtualenv with \u001b[31m\u001b[22mpipenv run\u001b[39m\u001b[22m.\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD9DO1Is9Edf",
        "colab_type": "code",
        "outputId": "75c9c885-e0e1-4611-fffb-963fbf234298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1367
        }
      },
      "source": [
        "#Run the training function. Output is the data dimension after each Convo & Dropout  operation has been applied. \n",
        "!pipenv run python train.py --epochs 10 --save_frequency 2 /content/data/cars/steelroses/collected #path to data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWarning\u001b[39m\u001b[22m: Your Pipfile requires \u001b[39m\u001b[1mpython_version\u001b[39m\u001b[22m \u001b[34m\u001b[22m3.*\u001b[39m\u001b[22m, but you are using \u001b[34m\u001b[22m3.6.7\u001b[39m\u001b[22m (\u001b[32m\u001b[22m/root/.local/share/v/f/bin/python\u001b[39m\u001b[22m).\n",
            "  \u001b[32m\u001b[22m$ pipenv --rm\u001b[39m\u001b[22m and rebuilding the virtual environment may resolve the issue.\n",
            "  \u001b[31m\u001b[22m$ pipenv check\u001b[39m\u001b[22m will surely fail.\n",
            "Using TensorFlow backend.\n",
            "tcmalloc: large alloc 6994501632 bytes == 0x5326000 @  0x7ffb7d38a001 0x7ffb7add1de5 0x7ffb7ae366f1 0x7ffb7ae387cf 0x7ffb7aed1158 0x5030d5 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7ffb7cf85b97 0x5afa0a\n",
            "tcmalloc: large alloc 3497254912 bytes == 0x1a61a0000 @  0x7ffb7d3881e7 0x7ffb7add1ca1 0x7ffb7ae39580 0x7ffb7aec9a82 0x5030d5 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7ffb7cf85b97 0x5afa0a\n",
            "adding first convolutional layer\n",
            "WARNING:tensorflow:From /root/.local/share/virtualenvs/foocars--MKvUarz/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /root/.local/share/virtualenvs/foocars--MKvUarz/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "adding second convolutional layer\n",
            "adding third convolutional layer\n",
            "adding fourth convolutional layer\n",
            "adding fifth convolutional layer\n",
            "adding fully connected layer\n",
            "adding output layer\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 18, 64, 24)        1824      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 18, 64, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 9, 32, 32)         19232     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 32, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 5, 16, 40)         32040     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 16, 40)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 8, 48)          17328     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 3, 8, 48)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 4, 48)          20784     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2, 4, 48)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               38500     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 129,809\n",
            "Trainable params: 129,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "starting epoch 0\n",
            "WARNING:tensorflow:From /root/.local/share/virtualenvs/foocars--MKvUarz/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 56921 samples, validate on 6325 samples\n",
            "Epoch 1/1\n",
            "2019-06-11 00:53:40.143743: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-06-11 00:53:40.236196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-11 00:53:40.242773: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2df0840 executing computations on platform Host. Devices:\n",
            "2019-06-11 00:53:40.242816: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-06-11 00:53:41.182943: W tensorflow/core/framework/allocator.cc:124] Allocation of 20480000 exceeds 10% of system memory.\n",
            "2019-06-11 00:53:41.182883: W tensorflow/core/framework/allocator.cc:124] Allocation of 20480000 exceeds 10% of system memory.\n",
            "2019-06-11 00:53:41.257264: W tensorflow/core/framework/allocator.cc:124] Allocation of 27648000 exceeds 10% of system memory.\n",
            "2019-06-11 00:53:41.259602: W tensorflow/core/framework/allocator.cc:124] Allocation of 23500800 exceeds 10% of system memory.\n",
            "   25/56921 [..............................] - ETA: 45:49 - loss: 0.6664 - mean_squared_error: 0.66642019-06-11 00:53:41.640574: W tensorflow/core/framework/allocator.cc:124] Allocation of 20480000 exceeds 10% of system memory.\n",
            "56921/56921 [==============================] - 925s 16ms/step - loss: 0.6843 - mean_squared_error: 0.6843 - val_loss: 2.9410 - val_mean_squared_error: 2.9410\n",
            "Saving epoch 0 to weights_2019-06-11_00-53-07_epoch_0.h5\n",
            "starting epoch 1\n",
            "Train on 56921 samples, validate on 6325 samples\n",
            "Epoch 1/1\n",
            "55225/56921 [============================>.] - ETA: 26s - loss: 0.5724 - mean_squared_error: 0.5724"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Un0mi-x8RZ",
        "colab_type": "code",
        "outputId": "9a88db44-a6d5-475a-ce69-5731da09fa24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip list | grep tensor #check Tensorflow is installed\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow          0.0.5                \n",
            "tensor2tensor            1.11.0               \n",
            "tensorboard              1.13.1               \n",
            "tensorboardcolab         0.0.22               \n",
            "tensorflow               1.13.1               \n",
            "tensorflow-estimator     1.13.0               \n",
            "tensorflow-hub           0.4.0                \n",
            "tensorflow-metadata      0.13.0               \n",
            "tensorflow-probability   0.6.0                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InYmY9lkxmrc",
        "colab_type": "text"
      },
      "source": [
        "## What are steerstats \n",
        "\n",
        "Let's look"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7U8sqpxrd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vVZnbXmxs0j",
        "colab_type": "text"
      },
      "source": [
        "## Download weights and steerstats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAwcWUHr7-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from skimage import io\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0GBQCFNyOOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get car files and download\n",
        "!tar cvzf car.weights.tar.gz *.h5 *.npz\n",
        "!rm *.h5 *.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuf8QyfuzGb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove results\n",
        "!rm *.h5 *.npz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs0qI4NjzNJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/data/cars/steelroses/model\n",
        "!tar xvzf car.weights.tar.gz -C /content/data/cars/steelroses/model/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4By3H84LymGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('car.weights.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdEHNyjI0CWk",
        "colab_type": "text"
      },
      "source": [
        "## Examine the weights and steer stats\n",
        "\n",
        "What does the computer think should happen?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwiGnlcR0KOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steerstats = np.load('/content/data/cars/steelroses/model/steerstats.npz')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZLhj4v40xKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(steerstats))\n",
        "steerstats.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ6E_aUI1UVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steerstats['arr_0'][0:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKHhp7de7SJJ",
        "colab_type": "text"
      },
      "source": [
        "## Examine the collected data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2jjkl1f49Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# commands.npz\n",
        "commands = np.load('/content/data/cars/steelroses/collected/commands_2018-12-06_12-54-17.npz'  )\n",
        "print(type(commands))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4b5nQBX5Cqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(commands.keys())\n",
        "commands['arr_0'][0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgx1KXBF5Cxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IME npz\n",
        "imu = np.load('/content/data/cars/steelroses/collected/IMU_2018-12-06_12-54-17.npz')\n",
        "print(type(imu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzXYqEaZ4F1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(imu.keys())\n",
        "imu['arr_0'][0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqU42eNG4axC",
        "colab_type": "text"
      },
      "source": [
        "## What images were collected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-t3B0jt4dQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.load('/content/data/cars/steelroses/collected/imgs_2018-12-06_12-54-17.npz')\n",
        "print(type(images))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqAWBP0n4q_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(images.keys())\n",
        "images['arr_0'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4qWGFfM8Aml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image3 = np.reshape(image3, (8,8,3))\n",
        "imgplot = plt.imshow(images['arr_0'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBfxHmSS-0e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Make a video clip\n",
        "# Tutorial: https://www.apriorit.com/dev-blog/600-colab-for-video-processing\n",
        "\n",
        "import cv2\n",
        "#import skimage.io\n",
        "#from matplotlib.patches import Polygon\n",
        "# VIDEO_FORMAT = \"MP4V\"\n",
        "# VIDEO_EXT = 'mp4'\n",
        "\n",
        "VIDEO_FORMAT = 'VP90'\n",
        "VIDEO_EXT = 'webm'\n",
        "\n",
        "VIDEO_OUT = '/content/data/output.' + VIDEO_EXT\n",
        "IMG_IN = '/content/data/cars/steelroses/collected/imgs_2018-12-06_12-54-17.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTM4FmEE__f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = images['arr_0'][0]\n",
        "print(image.shape)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*VIDEO_FORMAT)\n",
        "writer = cv2.VideoWriter(VIDEO_OUT, fourcc, 30, (image.shape[1], image.shape[0]), True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-EyQB0iIe0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imgdata = np.load(IMG_IN)['arr_0'].astype('float32')\n",
        "imgdata = np.load(IMG_IN)['arr_0']\n",
        "print(f'\\nShape: {imgdata.shape}\\n')\n",
        "\n",
        "\n",
        "#ITERATE  the first dimension and get the image from the rest\n",
        "for index in tqdm(range(0,len(imgdata))):\n",
        "  img = imgdata[index]\n",
        "  writer.write(img)\n",
        "\n",
        "writer.release()\n",
        "print(f'Done: {VIDEO_OUT}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbYspbgSWXTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!ls /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVkn-ZcctBnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save video locally\n",
        "from google.colab import files\n",
        "files.download(VIDEO_OUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuwUvkWLcrmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.display import Video\n",
        "\n",
        "Video(VIDEO_OUT)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTPyX9i8YTVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dynamic video tag is not showing. Maybe, do this in javacsript\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "\n",
        "HTML_SRC = \"\"\"<video width=\"400\" height=\"200\">\n",
        "<source src=\"/content/data/output.webm\" type=\"video/x-webm\"></source>\n",
        "</video>\"\"\"\n",
        "print(HTML_SRC)\n",
        "\n",
        "\n",
        "\n",
        "             \n",
        "display(HTML(HTML_SRC))             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3jiLd13thvA",
        "colab_type": "text"
      },
      "source": [
        "# Consulting the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMoFo8XN3sO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import concurrent.futures\n",
        "from dropout_model import model\n",
        "from defines import *\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2hRE_HVwSkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls /content/data/cars/steelroses/model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FreGpfk_vvas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '/content/data/cars'\n",
        "CAR_NAME = 'steelroses'\n",
        "WEIGHTS_DIR = DATA_DIR + \"/\" + CAR_NAME + '/model/'\n",
        "WEIGHTS_FILE = WEIGHTS_DIR + 'weights_2019-04-06_13-00-23_epoch_4.h5'\n",
        "STEERSTATS_FILE = DATA_DIR + \"/\" + CAR_NAME + '/model/steerstats.npz'\n",
        "print(WEIGHTS_FILE)\n",
        "print(STEERSTATS_FILE)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y01QwVTmxdTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Dropout Model\n",
        "# https://github.com/fubarlabs/foocars/blob/1e6b2bccac5b8595fd053816d9117169d35ae3a1/training/dropout_model.py\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.layers import Embedding, Input, merge\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "nrows=36\n",
        "ncols=128\n",
        "wr=0.00001 # l1 regularizer value\n",
        "dp=0.125 # dropout rate \n",
        "\n",
        "# Note: Dan used the keras functional paradigm to define his network.\n",
        "# I'm using the sequential paradigm. \n",
        "model=Sequential()\n",
        "frame_in = Input(shape=(3, nrows, ncols), name='img_input')\n",
        "\n",
        "#we should do a local contrast normalization\n",
        "\n",
        "print(\"adding first convolutional layer\")\n",
        "#5x5 convolutional layer with a stride of 2\n",
        "#model.add(BatchNormalization(input_shape=(nrows, ncols, 3)))\n",
        "model.add(Conv2D(24, (5, 5), input_shape=(nrows, ncols, 3), strides=(2, 2), activation='elu', padding='same', kernel_initializer='lecun_uniform'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "print(\"adding second convolutional layer\")\n",
        "#5x5 convolutional layer with a stride of 2\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (5, 5), strides=(2, 2), activation='elu', padding='same', kernel_initializer='lecun_uniform'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "print(\"adding third convolutional layer\")\n",
        "#5x5 convolutional layer with a stride of 2\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(40, (5, 5), strides=(2, 2), activation='elu', padding='same', kernel_initializer='lecun_uniform'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "print(\"adding fourth convolutional layer\")\n",
        "#3x3 convolutional layer with no stride \n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(48, (3, 3), strides=(2, 2), activation='elu', padding='same', kernel_initializer='lecun_uniform'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "print(\"adding fifth convolutional layer\")\n",
        "#3x3 convolutional layer with no stride \n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(48, (3, 3), strides=(2, 2), activation='elu', padding='same', kernel_initializer='lecun_uniform'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "print(\"adding fully connected layer\")\n",
        "#fully connected layer\n",
        "model.add(Dense(100, activation='elu', kernel_initializer='lecun_uniform'))\n",
        "model.add(Dropout(dp))\n",
        "\n",
        "print(\"adding output layer\")\n",
        "#fully connected layer to output node\n",
        "model.add(Dense(1, activation='linear', kernel_initializer='lecun_uniform'))\n",
        "\n",
        "model.compile(loss=['mse'], optimizer=SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True), metrics=['mse'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKfqNzEcuk_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model.load_weights(WEIGHTS_FILE)\n",
        "  model._make_predict_function()\n",
        "  global g_steerstats\n",
        "  g_steerstats=np.load(STEERSTATS_FILE)['arr_0']\n",
        "  \n",
        "  #g_camera=picamera.PiCamera()\n",
        "  #g_camera.resolution=(128, 96)\n",
        "  #g_camera.framerate=FRAME_RATE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqAQZOVQyseX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defines image size:\n",
        "row_offset=30\n",
        "nrows=36\n",
        "ncols=128\n",
        "\n",
        "\n",
        "#imgdata = np.load(IMG_IN)['arr_0'].astype('float32')\n",
        "imgdata = np.load(IMG_IN)['arr_0']\n",
        "print(f'\\nShape: {imgdata.shape}\\n')\n",
        "\n",
        "index = 1\n",
        "img = imgdata[index]\n",
        "\n",
        "# Image must be in the shape the model is using\n",
        "#ValueError: Error when checking input: expected conv2d_6_input to have shape (36, 128, 3) but got array with shape (96, 128, 3)\n",
        "# original image shape (200, 96, 128, 3)\n",
        "\n",
        "#imagerawdata=np.reshape(np.fromstring(s, dtype=np.uint8), (96, 128, 3), 'C')\n",
        "#imdata=imagerawdata[20:56, :]\n",
        "\n",
        "immean=img.mean()\n",
        "imvar=img.std()\n",
        "g_imageData=np.copy((imgdata-immean)/imvar)\n",
        "fimg = g_imageData[0]\n",
        "\n",
        "crop_image=fimg[row_offset:row_offset+nrows, :]\n",
        "image_mean=crop_image.mean()\n",
        "image_std=crop_image.std()\n",
        "guess_image=(crop_image-image_mean)/image_std\n",
        "\n",
        "\n",
        "#The actual prediction\n",
        "pred=model.predict(np.expand_dims(guess_image, axis=0))      \n",
        "steer_command=pred[0][0]*g_steerstats[1]+g_steerstats[0]\n",
        "\n",
        "print(f'pred: {pred}, steer: {steer_command}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGeHrKAciWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}